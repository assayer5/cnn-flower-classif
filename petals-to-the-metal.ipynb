{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook adapted from https://www.kaggle.com/code/ryanholbrook/create-your-first-submission/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:14.624477Z",
     "iopub.status.busy": "2022-07-09T22:43:14.623265Z",
     "iopub.status.idle": "2022-07-09T22:43:14.633111Z",
     "shell.execute_reply": "2022-07-09T22:43:14.631408Z",
     "shell.execute_reply.started": "2022-07-09T22:43:14.624414Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os, re, random\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:14.753231Z",
     "iopub.status.busy": "2022-07-09T22:43:14.752882Z",
     "iopub.status.idle": "2022-07-09T22:43:20.468955Z",
     "shell.execute_reply": "2022-07-09T22:43:20.467786Z",
     "shell.execute_reply.started": "2022-07-09T22:43:14.753177Z"
    }
   },
   "outputs": [],
   "source": [
    "# if available, connect to a TPU accelerator on the network (8 cores/TPU)\n",
    "# create strategy for distributed training over 8 cores of TPU\n",
    "try:\n",
    "    # google cloud TPU cluster resolver\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('running on TPU ', resolver.master())\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    \n",
    "except:\n",
    "    # if TPU unavailable, will get default strategy (single replica)\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print('replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:20.471504Z",
     "iopub.status.busy": "2022-07-09T22:43:20.471108Z",
     "iopub.status.idle": "2022-07-09T22:43:20.869318Z",
     "shell.execute_reply": "2022-07-09T22:43:20.867854Z",
     "shell.execute_reply.started": "2022-07-09T22:43:20.471454Z"
    }
   },
   "outputs": [],
   "source": [
    "# get google cloud storage path, data must be in GCS bucket to use TPUs\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\n",
    "print(GCS_DS_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:20.871700Z",
     "iopub.status.busy": "2022-07-09T22:43:20.871426Z",
     "iopub.status.idle": "2022-07-09T22:43:21.105803Z",
     "shell.execute_reply": "2022-07-09T22:43:21.104580Z",
     "shell.execute_reply.started": "2022-07-09T22:43:20.871669Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [512, 512]\n",
    "GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
    "# auto optimizes data consumption rate, gives number of free processors \n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# get lists of filenames\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n",
    "\n",
    "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
    "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
    "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
    "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
    "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
    "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
    "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
    "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
    "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
    "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
    "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:21.116900Z",
     "iopub.status.busy": "2022-07-09T22:43:21.116602Z",
     "iopub.status.idle": "2022-07-09T22:43:21.135458Z",
     "shell.execute_reply": "2022-07-09T22:43:21.134837Z",
     "shell.execute_reply.started": "2022-07-09T22:43:21.116870Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_augment(image, label):\n",
    "    # reduce overfitting \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)     \n",
    "    image = tf.image.random_contrast(image, 0.5, 2)\n",
    "    image = tf.image.random_saturation(image, 0.5, 5)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "#     crop = tf.image.random_crop(image, [int(IMAGE_SIZE[0]//1.5),int(IMAGE_SIZE[1]//1.5),3])\n",
    "#     image = tf.image.resize_with_crop_or_pad(crop, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "    \n",
    "    return image, label   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec\n",
    "    # files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:21.137764Z",
     "iopub.status.busy": "2022-07-09T22:43:21.136461Z",
     "iopub.status.idle": "2022-07-09T22:43:21.785985Z",
     "shell.execute_reply": "2022-07-09T22:43:21.785307Z",
     "shell.execute_reply.started": "2022-07-09T22:43:21.137699Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "ds_train = get_training_dataset()\n",
    "ds_valid = get_validation_dataset()\n",
    "ds_test = get_test_dataset()\n",
    "\n",
    "print(\"Training:\", ds_train)\n",
    "print (\"Validation:\", ds_valid)\n",
    "print(\"Test:\", ds_test)\n",
    "print('Batch size:', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:21.787393Z",
     "iopub.status.busy": "2022-07-09T22:43:21.787046Z",
     "iopub.status.idle": "2022-07-09T22:43:28.866610Z",
     "shell.execute_reply": "2022-07-09T22:43:28.865226Z",
     "shell.execute_reply.started": "2022-07-09T22:43:21.787362Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=15, linewidth=80)\n",
    "\n",
    "print(\"Training data shapes:\")\n",
    "for image, label in ds_train.take(3):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "print(\"Training data label examples:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:28.868784Z",
     "iopub.status.busy": "2022-07-09T22:43:28.868398Z",
     "iopub.status.idle": "2022-07-09T22:43:32.380141Z",
     "shell.execute_reply": "2022-07-09T22:43:32.379310Z",
     "shell.execute_reply.started": "2022-07-09T22:43:28.868736Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test data shapes:\")\n",
    "for image, idnum in ds_test.take(3):\n",
    "    print(image.numpy().shape, idnum.numpy().shape)\n",
    "print(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:32.382010Z",
     "iopub.status.busy": "2022-07-09T22:43:32.381481Z",
     "iopub.status.idle": "2022-07-09T22:43:36.919940Z",
     "shell.execute_reply": "2022-07-09T22:43:36.917901Z",
     "shell.execute_reply.started": "2022-07-09T22:43:32.381964Z"
    }
   },
   "outputs": [],
   "source": [
    "# visual check of sample of training images\n",
    "\n",
    "# make batches of 12 from training dataset\n",
    "sample_iter = iter(ds_train.unbatch().batch(12)) \n",
    "# get a single batch\n",
    "samplebatch = next(sample_iter) \n",
    "# convert to numpy\n",
    "samp_images, samp_labels = samplebatch\n",
    "samp_batch = zip(samp_images.numpy(), samp_labels.numpy())\n",
    "\n",
    "rows, cols = 3,4\n",
    "plt.figure(figsize=(15,15))\n",
    "item = 1\n",
    "for image, label in samp_batch:\n",
    "    plt.subplot(rows, cols, item)\n",
    "    plt.axis('off')\n",
    "    #plt.tight_layout()\n",
    "    plt.title(str(label))\n",
    "    plt.imshow(image)\n",
    "    item +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:36.923224Z",
     "iopub.status.busy": "2022-07-09T22:43:36.922921Z",
     "iopub.status.idle": "2022-07-09T22:43:46.891890Z",
     "shell.execute_reply": "2022-07-09T22:43:46.890805Z",
     "shell.execute_reply.started": "2022-07-09T22:43:36.923192Z"
    }
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    #pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(\n",
    "    pretrained_model = tf.keras.applications.Xception(\n",
    "    #pretrained_model = tf.keras.applications.InceptionV3(\n",
    "    #pretrained_model = tf.keras.applications.VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False ,\n",
    "        input_shape=[*IMAGE_SIZE, 3]\n",
    "    )\n",
    "    pretrained_model.trainable = False\n",
    "     \n",
    "    model = tf.keras.Sequential([\n",
    "        # To a base pretrained on ImageNet to extract features from images...\n",
    "        pretrained_model,\n",
    "        # ... attach a new head to act as a classifier.\n",
    "        \n",
    "        #tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        #tf.keras.layers.GlobalMaxPooling2D(),\n",
    "\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        \n",
    "        \n",
    "        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "        \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:46.893612Z",
     "iopub.status.busy": "2022-07-09T22:43:46.893312Z",
     "iopub.status.idle": "2022-07-09T22:43:46.957325Z",
     "shell.execute_reply": "2022-07-09T22:43:46.956155Z",
     "shell.execute_reply.started": "2022-07-09T22:43:46.893571Z"
    }
   },
   "outputs": [],
   "source": [
    "# set initial learning rate with optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:46.959353Z",
     "iopub.status.busy": "2022-07-09T22:43:46.958994Z",
     "iopub.status.idle": "2022-07-09T22:43:47.239983Z",
     "shell.execute_reply": "2022-07-09T22:43:47.238744Z",
     "shell.execute_reply.started": "2022-07-09T22:43:46.959310Z"
    }
   },
   "outputs": [],
   "source": [
    "# define learning rate function, uses current epoch and learning rate as inputs\n",
    "def learnrate(epoch, lr, \n",
    "              max_lr = 0.002, \n",
    "              min_lr= 0.0001, \n",
    "              sustain_epochs= 8, \n",
    "              exp_decay= 0.8):\n",
    "    \n",
    "    if epoch < sustain_epochs:\n",
    "        lr = max_lr\n",
    "    else:\n",
    "        lr = (max_lr - min_lr) * exp_decay**(epoch - sustain_epochs) + min_lr\n",
    "    return lr\n",
    "\n",
    "# plot of learning rate \n",
    "EPOCHS = 40\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [learnrate(x, 0.002) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(learnrate, verbose=True)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T22:43:47.244642Z",
     "iopub.status.busy": "2022-07-09T22:43:47.243835Z",
     "iopub.status.idle": "2022-07-09T23:01:12.171054Z",
     "shell.execute_reply": "2022-07-09T23:01:12.169853Z",
     "shell.execute_reply.started": "2022-07-09T22:43:47.244521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training epochs\n",
    "EPOCHS = 40\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    callbacks=[lr_callback, earlystop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T23:01:12.173652Z",
     "iopub.status.busy": "2022-07-09T23:01:12.173218Z",
     "iopub.status.idle": "2022-07-09T23:01:12.182889Z",
     "shell.execute_reply": "2022-07-09T23:01:12.181783Z",
     "shell.execute_reply.started": "2022-07-09T23:01:12.173586Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "    if subplot%10==1: # set up the subplots on the first call\n",
    "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.plot(training)\n",
    "    ax.plot(validation)\n",
    "    ax.set_title('model '+ title)\n",
    "    ax.set_ylabel(title)\n",
    "    #ax.set_ylim(0.28,1.05)\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.legend(['train', 'valid.'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T23:01:12.185400Z",
     "iopub.status.busy": "2022-07-09T23:01:12.184797Z",
     "iopub.status.idle": "2022-07-09T23:01:12.917349Z",
     "shell.execute_reply": "2022-07-09T23:01:12.916253Z",
     "shell.execute_reply.started": "2022-07-09T23:01:12.185349Z"
    }
   },
   "outputs": [],
   "source": [
    "display_training_curves(\n",
    "    history.history['loss'],\n",
    "    history.history['val_loss'],\n",
    "    'loss',\n",
    "    211,\n",
    ")\n",
    "display_training_curves(\n",
    "    history.history['sparse_categorical_accuracy'],\n",
    "    history.history['val_sparse_categorical_accuracy'],\n",
    "    'accuracy',\n",
    "    212,\n",
    ")\n",
    "\n",
    "plt.savefig('lossacc.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T23:01:12.920488Z",
     "iopub.status.busy": "2022-07-09T23:01:12.919832Z",
     "iopub.status.idle": "2022-07-09T23:01:12.941158Z",
     "shell.execute_reply": "2022-07-09T23:01:12.939673Z",
     "shell.execute_reply.started": "2022-07-09T23:01:12.920430Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def display_confusion_matrix(cmat, score, precision, recall):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    ax = plt.gca()\n",
    "    ax.matshow(cmat, cmap='Reds')\n",
    "    ax.set_xticks(range(len(CLASSES)))\n",
    "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
    "    ax.set_yticks(range(len(CLASSES)))\n",
    "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n",
    "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    titlestring = \"\"\n",
    "    if score is not None:\n",
    "        titlestring += 'f1 = {:.3f} '.format(score)\n",
    "    if precision is not None:\n",
    "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
    "    if recall is not None:\n",
    "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
    "    if len(titlestring) > 0:\n",
    "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T23:01:12.943274Z",
     "iopub.status.busy": "2022-07-09T23:01:12.942779Z",
     "iopub.status.idle": "2022-07-09T23:01:24.723765Z",
     "shell.execute_reply": "2022-07-09T23:01:24.721677Z",
     "shell.execute_reply.started": "2022-07-09T23:01:12.943237Z"
    }
   },
   "outputs": [],
   "source": [
    "cmdataset = get_validation_dataset(ordered=True)\n",
    "images_ds = cmdataset.map(lambda image, label: image)\n",
    "labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n",
    "\n",
    "cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy()\n",
    "cm_probabilities = model.predict(images_ds)\n",
    "cm_predictions = np.argmax(cm_probabilities, axis=-1)\n",
    "\n",
    "labels = range(len(CLASSES))\n",
    "cmat = confusion_matrix(\n",
    "    cm_correct_labels,\n",
    "    cm_predictions,\n",
    "    labels=labels,\n",
    ")\n",
    "cmat = (cmat.T / cmat.sum(axis=1)).T # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-09T23:01:24.725523Z",
     "iopub.status.busy": "2022-07-09T23:01:24.725253Z",
     "iopub.status.idle": "2022-07-09T23:01:30.371157Z",
     "shell.execute_reply": "2022-07-09T23:01:30.369585Z",
     "shell.execute_reply.started": "2022-07-09T23:01:24.725494Z"
    }
   },
   "outputs": [],
   "source": [
    "score = f1_score(\n",
    "    cm_correct_labels,\n",
    "    cm_predictions,\n",
    "    labels=labels,\n",
    "    average='macro',\n",
    ")\n",
    "precision = precision_score(\n",
    "    cm_correct_labels,\n",
    "    cm_predictions,\n",
    "    labels=labels,\n",
    "    average='macro',\n",
    ")\n",
    "recall = recall_score(\n",
    "    cm_correct_labels,\n",
    "    cm_predictions,\n",
    "    labels=labels,\n",
    "    average='macro',\n",
    ")\n",
    "display_confusion_matrix(cmat, score, precision, recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
